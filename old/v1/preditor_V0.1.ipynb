{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Preditor de Evasão Estudantil\nEste projeto pretende identificar os estudantes da graduação da Universidade de Brasília com risco de evasão a partir do histórico acadêmico. Leia atentamente este guia para executar os algoritmos.\n\n### Como usar\nPrimeiro, é necessário adicionar os dados dos estudantes a este notebook. Para isso, clique no botão `Copy and Edit`, que o levará a uma página para edição do notebook. Nessa página, clique no botão `+ Add Data`. São necessários três arquivos CSV para rodar os algoritmos: `training_data.csv`, `test_data.csv` e `materias.csv`. Criei um arquivo ZIP com os três arquivos e faça o upload.\n\n#### training_data.csv\nO `training_data.csv` contém os dados dos estudantes que já terminaram o curso, evadidos ou formados. O formato do `training_data.csv` segue abaixo:\n\n| IdAluno | SemestreIngresso | SemestreMateria |  CodigoMateria | Conceito | StatusFinal |\n|---------|------------------|-----------------|----------------|----------|-------------|\n| 1234    | 20101            | 20102           |  113034        | \"SS\"     | \"FORMADO\"   |\n| 1235    | 20112            | 20121           |  118028        | \"II\"     | \"EVADIDO\"   |\n\n+ **IdAluno** (*inteiro*): identificador único de um aluno\n+ **SemestreIngresso** (*inteiro*): o semestre de ingresso do aluno no curso de graduação. Esse campo deve seguir o formato `AAAAS`, onde `A` é um dígito do ano e `S` é o semestre, e.g. '20101' para um aluno que ingressou no 1º semestre de 2010.\n+ **SemestreMateria** (*inteiro*): o semestre no qual o aluno cursou determinada matéria. Esse campo deve seguir o formato `AAAAS`, onde `A` é um dígito do ano e `S` é o semestre.\n+ **CodigoMateria** (*inteiro*): o código da matéria. Verifique os códigos das matérias no [Matrícula Web](https://matriculaweb.unb.br/).\n+ **Conceito** (*string*): menção do aluno naquela matéria no semestre.\n+ **StatusFinal** (*string*): o status do aluno ao final do curso. Os possíveis valores para este campo devem ser:\n  + Se formado => `FORMADO`\n  + Se evadido => `EVADIDO`\n\nNo exemplo acima, o estudante 1234, que formou, entrou no 1º semestre de 2010 e cursou a matéria com código 113034 (Cálculo 1) no 2º semestre de 2010 e obteve a menção SS. A segunda linha mostra que o estudante evadido 1235 entrou no 2º semestre de 2011 e cursou 118028 (Física 2) no 1º semestre de 2012 e obteve II.\n\n#### test_data.csv\nO arquivo `test_data` contém os dados dos alunos que estão ativos e que desejam ser classificados em evadidos ou formados. Esse arquivo tem o mesmo formato do `training_data.csv` excetuando a coluna `StatusFinal`, que não está presente.\n\n#### materias.csv\nO arquivo `materias.csv` tem as matérias contidas nos dados de treinamento e teste. **O algoritmo utilizará as matérias que estão nesse arquivo. Recomenda-se usar as matérias obrigatórias dos dois primeiros semestres do curso.** O formato do arquivo é:\n\n| CodigoMateria | Creditos |\n|---------------|----------|\n| 113034        | 6        |\n| 118028        | 4        |\n\n#### Observações\n+ Alunos que vieram a falecer não devem ser usados na entrada.\n+ Todos os estudantes devem estar matriculados no mesmo curso de graduação.\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ninput_train_df = pd.read_csv('../input/mecatronics-bi-dump/training_data.csv')\ninput_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataframe para o treinamento dos algoritmos de classificação"},{"metadata":{"trusted":true},"cell_type":"code","source":"materias_df = pd.read_csv('../input/mecatronics-bi-dump/materias.csv')\n\ndef calculate(entry_semester, course_semester):\n    if is_summer_course(course_semester):\n        course_semester += 1\n\n    diff = course_semester - entry_semester\n\n    if entry_semester % 2 != 0 :\n        if diff >= 10 :\n            result = semesters_between_years(diff)\n        else:\n            result = diff\n    else:\n        if diff % 10 == 0 :\n            result = semesters_between_years(diff)\n        else:\n            result = diff // 5\n\n    return result + 1\n\ndef is_summer_course(semester):\n    return semester % 10 == 0\n\ndef semesters_between_years(diff):\n    return (diff // 5) + (diff % 5)\n\ndef transform_dataframe(df, aggfunc, fill_value, groupby_columns):\n    df['CourseTerm'] = df.Semester.map(str) + '_' + df.CodigoMateria.map(str)\n    df = df.drop(columns=['SemestreIngresso', 'SemestreMateria', 'CodigoMateria', 'Semester'])\n\n    df = df.pivot_table(values='Conceito', index=groupby_columns, columns='CourseTerm', aggfunc=aggfunc, fill_value=fill_value)\n    df.columns.name = None\n    return df.reset_index()\n\ndef failed_workload(row, semester=None):\n    failed_workload = 0\n\n    for code, workload in list(zip(materias_df['CodigoMateria'], materias_df['Creditos'])):\n        if semester == None:\n            if '1_' + str(code) in row: failed_workload += row['1_' + str(code)] * workload\n            if '2_' + str(code) in row: failed_workload += row['2_' + str(code)] * workload\n        else:\n            if semester + '_' + str(code) in row: failed_workload += row[semester + '_' + str(code)] * workload\n\n    return failed_workload\n\ndef calculate_semester(df):\n    df['Semester'] = df.apply(lambda x: calculate(x['SemestreIngresso'], x['SemestreMateria']), axis=1)\n    return df[(df.Semester > 0) & (df.Semester <= 2)]\n\ndef one_hot_encoding(df, groupby_columns):\n    columns = df.columns.difference(groupby_columns).tolist()\n    for column in columns:\n        one_hot = pd.get_dummies(df[column])\n        df = df.drop(column,axis = 1)\n        one_hot.columns = map(lambda x: column + '_' + x, one_hot.columns)\n        df = df.join(one_hot)\n    return df\n\ndef calculate_failed_workload(df, aux_df, groupby_columns):\n    aux_df['Conceito'] = aux_df['Conceito'].replace(['SR', 'II', 'MI'], 1)\n    aux_df['Conceito'] = aux_df['Conceito'].replace(['SS', 'MS', 'MM', 'CC', 'DP', 'TR', 'TJ'], 0)\n    aux_df = transform_dataframe(aux_df, 'sum', 0, groupby_columns)\n    \n    df['Creditos_Reprovados'] = aux_df.apply(lambda row: failed_workload(row), axis=1)\n    df['Creditos_Reprovados_1'] = aux_df.apply(lambda row: failed_workload(row, '1'), axis=1)\n    df['Creditos_Reprovados_2'] = aux_df.apply(lambda row: failed_workload(row, '2'), axis=1)\n    \n    return df\n\ndef model_data(df, groupby_columns=['IdAluno', 'StatusFinal']):\n    aux_df = df.copy()\n    df = transform_dataframe(df, 'last', 'NC', groupby_columns)\n    df = one_hot_encoding(df, groupby_columns)\n    df = calculate_failed_workload(df, aux_df, groupby_columns)\n    \n    return df\n\ninput_train_df = calculate_semester(input_train_df)\ntrain_df = model_data(input_train_df)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, recall_score\nfrom sklearn.preprocessing import StandardScaler\n\n\nscaler = StandardScaler()\n\nlogreg_param_grid = {\n    'solver': ['liblinear', 'lbfgs'],\n    'C': np.logspace(-2, 4, 10)\n}\n\n\ndtree_param_grid = {\n    'criterion': ['gini', 'entropy'],\n    'splitter': ['best', 'random'],\n    'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)\n}\n\nrf_param_grid = {\n    'criterion': ['gini', 'entropy'],\n    'n_estimators': range(10,200,20),\n    'max_features': ['auto', 'sqrt']\n}\n\nclassifiers = [\n    ('LogisticRegression', LogisticRegression(max_iter=1500), logreg_param_grid),\n    ('DecisionTreeClassifier', tree.DecisionTreeClassifier(), dtree_param_grid),\n    ('RandomForestClassifier', RandomForestClassifier(), rf_param_grid)\n]\n\nfeature_cols = train_df.columns.difference(['StatusFinal', 'IdAluno'])\nfeatures = train_df.loc[:, feature_cols]\nlabels = train_df.StatusFinal.replace({'EVADIDO': 1, 'FORMADO': 0})\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.30, stratify=labels, random_state=42)\n\nscaler.fit(X_train.values)\nX_train = scaler.transform(X_train.values)\nX_test = scaler.transform(X_test.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Treinamento e validação dos classificadores:\n- [sensibilidade](https://en.wikipedia.org/wiki/Precision_and_recall#Recall): porcentagem dos estudantes que realmente vão evadir que foram classificados corretamente\n- [acurácia](https://en.wikipedia.org/wiki/Accuracy_and_precision): habilidade do algoritmo de classificar os estudantes corretamente\n\nComo o objetivo é encontrar o maior número possível de estudantes que realmente vão evadir, treinamos os classificadores para **maximizar a sensibilidade**."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_classifiers = []\nfor classifier in classifiers:\n    grid_search = GridSearchCV(classifier[1], classifier[2], scoring='recall',\n                          cv=10, return_train_score=True, iid=True)\n    grid_search.fit(X_train, y_train.values)\n\n    y_pred = grid_search.predict(X_test)\n    print(classifier[0])\n    print('Melhores parametros para sensibilidade', grid_search.best_params_)\n    print(\"sensibilidade = %0.4f\" % recall_score(y_test.values, y_pred))\n    print(\"acurácia = %0.4f\" % accuracy_score(y_test.values, y_pred))\n    best_classifiers.append(grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora lemos os dados de treinamento e fazemos as previsões."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/mecatronics-bi-dump/test_data.csv')\ntest_df = calculate_semester(test_df)\ntest_df = model_data(test_df, ['IdAluno'])\nremaining_columns = train_df.columns.difference(test_df.columns).tolist()\nremaining_columns.remove('StatusFinal')\nfor column in remaining_columns:\n    test_df[column] = 0\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = test_df.columns.difference(['IdAluno'])\nfeatures = test_df.loc[:, feature_cols]\n\npredictions = []\nfor classifier in best_classifiers:\n    predictions.append(classifier.predict(features))\n\nresults_df = pd.DataFrame(columns=['IdAluno', 'Regressao Logistica', 'Arvores de Decisao', 'Florestas Aleatorias'])\nindex = 0\nfor student in range(test_df.shape[0]):\n    results_df.loc[index] = [test_df['IdAluno'][index]] + \\\n                                ['EVADIDO' if predictions[0][index] else 'FORMADO'] + \\\n                                ['EVADIDO' if predictions[1][index] else 'FORMADO'] + \\\n                                ['EVADIDO' if predictions[2][index] else 'FORMADO']\n    index += 1\n\nresults_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regras de associação\nO aprendizado de regras de associação é um método de aprendizado de máquina baseado em regras para descobrir relações interessantes entre variáveis ​​em grandes bancos de dados. [Mais informações](https://en.wikipedia.org/wiki/Association_rule_learning)."},{"metadata":{"trusted":true},"cell_type":"code","source":"association_df = input_train_df.copy()\n\nassociation_df = association_df.drop(columns=['SemestreIngresso', 'SemestreMateria'])\nassociation_df = association_df.applymap(str)\n\nassociation_df['TermCourseGrade'] = association_df.Semester + '_' + association_df.CodigoMateria + '_' + association_df.Conceito\nassociation_df = association_df.drop(columns=['Conceito', 'CodigoMateria', 'Semester'])\n\ngrouped = association_df.groupby(['IdAluno', 'StatusFinal'])\nassociation_df = grouped['TermCourseGrade'].apply(lambda x: pd.Series(x.values)).unstack()\nassociation_df = association_df.reset_index()\n\nassociation_df = association_df.drop(columns=['IdAluno'])\nassociation_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from apyori import apriori\n\nrecords = association_df.T.apply(lambda x: x.dropna().tolist()).tolist()\nrules = apriori(records, min_support=0.03, min_confidence=0.8)\nrules_df = pd.DataFrame(columns=('Antecedent','Consequent','Support','Confidence'))\nSupport =[]\nConfidence = []\nAntecedent = []\nConsequent=[]\n\nfor RelationRecord in rules:\n    for ordered_stat in RelationRecord.ordered_statistics:\n        Support.append(RelationRecord.support)\n        Antecedent.append(list(ordered_stat.items_base))\n        Consequent.append(ordered_stat.items_add)\n        Confidence.append(ordered_stat.confidence)\n                             \nrules_df['Antecedent'] = list(Antecedent)\nrules_df['Consequent'] = Consequent\nrules_df['Support'] = Support\nrules_df['Confidence'] = Confidence\n\nrules_df.sort_values(by =['Confidence', 'Support'], ascending = False, inplace = True)\n\nrules_df = rules_df[rules_df['Consequent'] == {'EVADIDO'}]\n\nfor index, row in rules_df.iterrows():\n    antecedents = [antecedent.split('_') for antecedent in row.Antecedent]\n    for i, antecedent in enumerate(antecedents, start=0):\n        if i == 0: print('se tirou ', end='')\n        else: print(' e tirou ', end='')\n        print('%s em %s no %sº semestre' % (antecedent[2],antecedent[1],antecedent[0]), end='')\n    print(', então será %s com %s%% de confiança => %s casos' % (list(row.Consequent)[0], round(row.Confidence * 100, 2), round(row.Support * association_df.shape[0], 0)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui temos as regras de associação obtidas a partir dos dados de treinamento, ou seja, dos dados do passado do curso. Por exemplo, uma linha\n\n| Se          | Entao   | Confiança | Ocorrencias |\n|-------------|---------|-----------|-------------|\n| 1_113034_II | EVADIDO | 96.153846 | 50.0        |\n\nsignifica que se um aluno tiver tirado II em 113034 (Cálculo 1) no seu 1º semestre, ele tem chances de evadir com 96% de confiança e isso aconteceu 50 vezes nos dados.\n\n[**Confiança**](https://en.wikipedia.org/wiki/Association_rule_learning#Confidence) é uma indicação de quantas vezes a regra foi considerada verdadeira. No nosso exemplo, é a proporção de vezes que estudantes tinham 1_113034_II no seu histórico e evadiram sobre a quantidade de vezes que alunos tinham 1_113034_II."},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}